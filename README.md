# Compte Rendu TP4 : Experiment Tracking avec MLflow


## Introduction

Ce TP a pour objectif de mettre en place un pipeline MLOps pour le tracking d'exp√©riences de Computer Vision, en utilisant :
- **MLflow** pour le tracking des exp√©riences et le Model Registry
- **DVC** pour le versioning des datasets
- **MinIO** comme stockage S3-compatible pour les artifacts
- **YOLO (Ultralytics)** pour la d√©tection d'objets (classe `person`)

Le projet vise √† comparer diff√©rentes configurations d'hyperparam√®tres et √† s√©lectionner le meilleur mod√®le pour la production.

---

## Configuration de l'environnement

### 1. Cr√©ation et activation de l'environnement virtuel Anaconda

```bash
conda activate agents
```

J'ai travaill√© dans un environnement virtuel Anaconda nomm√© **`agents`** pour isoler les d√©pendances du projet.

### 2. Installation des d√©pendances

```bash
pip install -r requirements.txt
```

**Contenu de `requirements.txt`** :
- `mlflow>=2.10,<3.0` : Tracking des exp√©riences et Model Registry
- `ultralytics>=8.1.0,<9.0` : Framework YOLO pour la d√©tection d'objets
- `opencv-python`, `numpy`, `pandas`, `matplotlib` : Traitement d'images et visualisation
- `pyyaml`, `pillow`, `requests` : Utilitaires

### 3. D√©marrage de l'infrastructure MLflow + MinIO

```bash
docker compose up -d
```

Cette commande lance deux conteneurs Docker :

**Conteneur MLflow** (`mlflow:5000`) :
- Interface web pour visualiser les exp√©riences
- Backend SQLite pour les m√©tadonn√©es
- Stockage local des artifacts dans `/mlflow/artifacts`

**Conteneur MinIO** (`minio:9000`, console `9001`) :
- Stockage S3-compatible pour les artifacts
- Identifiants : `minio` / `minio12345`

---

## Pr√©paration du dataset

### G√©n√©ration du dataset minimal COCO ‚Üí Tiny Person

```bash
python tools/make_tiny_person_from_coco128.py
```

**Ce script effectue** :
1. T√©l√©charge/utilise le dataset COCO128 (128 images d'entra√Ænement)
2. Filtre uniquement la classe **`person`** (label `0`)
3. R√©organise les images et labels dans la structure YOLO :
   ```
   data/tiny_coco/
   ‚îú‚îÄ‚îÄ images/
   ‚îÇ   ‚îú‚îÄ‚îÄ train/   (128 images)
   ‚îÇ   ‚îú‚îÄ‚îÄ val/     (128 images de validation)
   ‚îÇ   ‚îî‚îÄ‚îÄ test/    (128 images de test)
   ‚îî‚îÄ‚îÄ labels/
       ‚îú‚îÄ‚îÄ train/   (annotations YOLO format)
       ‚îú‚îÄ‚îÄ val/
       ‚îî‚îÄ‚îÄ test/
   ```
4. G√©n√®re le fichier de configuration `data/tiny_coco.yaml` :
   ```yaml
   path: data/tiny_coco
   train: images/train
   val: images/val
   test: images/test
   names:
     0: person
   ```

**R√©sultat** : Dataset l√©ger avec **une seule classe** (`person`) pour acc√©l√©rer les exp√©rimentations.

---

## Tracking du dataset avec DVC

### Initialisation de DVC

```bash
dvc init
```

Initialise DVC dans le projet Git pour versionner les donn√©es volumineuses.

### Ajout du dataset au tracking

```bash
dvc add data/tiny_coco
```

**Effet** :
- Cr√©e `data/tiny_coco.dvc` contenant le hash MD5 du dossier :
  ```
  outs:
  - md5: 0b1b46742dcb489bd65a2a6ef495f646.dir
    size: 2198213
    nfiles: 120
    hash: md5
    path: tiny_coco
  ```
- Met √† jour `.gitignore` pour exclure `data/tiny_coco/` (seul le `.dvc` sera versionn√©)

### Commit Git

```bash
git add data/tiny_coco.dvc .gitignore
git commit -m "Add tiny_coco dataset tracked with DVC"
```

### Push vers le remote S3 (MinIO)

![Capture 1 - DVC Push](captures/1.png)

```bash
dvc push
```

**Configuration pr√©alable** (TP pr√©c√©dent) :
```bash
dvc remote add -d myremote s3://mlops-dvc
dvc remote modify myremote endpointurl http://localhost:9000
dvc remote modify myremote access_key_id minio
dvc remote modify myremote secret_access_key minio12345
```

**R√©sultat** : Le dataset `tiny_coco` est sauvegard√© sur le bucket S3 `mlops-dvc`, permettant la reproductibilit√© et le partage avec l'√©quipe.

---

## Entra√Ænement baseline

### Lancement du premier run

![Capture 2 - Run Baseline](captures/2.png)

```bash
python -m src.train_cv --epochs 3 --imgsz 320 --exp-name cv_yolo_tiny
```

**Param√®tres par d√©faut** :
- `--model yolov8n.pt` : YOLO v8 Nano (l√©ger)
- `--epochs 3` : Entra√Ænement rapide (budget limit√©)
- `--imgsz 320` : R√©solution d'entr√©e 320√ó320
- `--lr0 0.005` : Learning rate initial
- `--batch 8` : Taille de batch
- `--seed 42` : Seed al√©atoire pour reproductibilit√©

**Ce que fait `src/train_cv.py`** :
1. **Fixe le seed** (`set_global_seed`) pour reproductibilit√©
2. **Cr√©e une exp√©rience MLflow** nomm√©e `cv_yolo_tiny`
3. **Log les param√®tres** : `model`, `epochs`, `imgsz`, `lr0`, `batch`, `seed`, `data`
4. **Entra√Æne le mod√®le YOLO** avec Ultralytics
5. **Log les m√©triques finales** :
   - `precision`, `recall`, `mAP50`, `mAP50-95` (epoch 3)
6. **Log les artifacts** :
   - `results.png`, `confusion_matrix.png`, `PR_curve.png`
   - `weights/best.pt` (meilleur checkpoint)

**R√©sultat** :
- Run visible dans MLflow UI (`http://localhost:5000`)
- Fichiers locaux dans `runs/detect/yolov8n_e3_sz320_lr0.005_s42/`

---

## Recherche d'hyperparam√®tres (Grid Search)

### Pr√©paration du script

```bash
chmod +x scripts/run_grid.sh
```

### Lancement de la grille de 8 runs

![Capture 3 - Grid Search](captures/3.png)

```bash
bash scripts/run_grid.sh
```

### Explication du script `run_grid.sh`

```bash
#!/usr/bin/env bash
set -e

# Grille : 2 tailles √ó 2 learning rates √ó 2 seeds = 8 runs
for SIZE in 320 416; do
  for LR in 0.005 0.010; do
    for SEED in 1 42; do
      python -u src/train_cv.py --data data/tiny_coco.yaml \
        --model yolov8n.pt --epochs 3 --imgsz $SIZE --lr0 $LR --seed $SEED \
        --exp-name cv_yolo_tiny
    done
  done
done
```

**Logique du script** :
1. **Boucles imbriqu√©es** : Teste toutes les combinaisons de :
   - **Image size** : 320√ó320 et 416√ó416
   - **Learning rate** : 0.005 et 0.01
   - **Random seed** : 1 et 42 (pour v√©rifier la reproductibilit√©)

2. **Options importantes** :
   - `set -e` : Arr√™te le script si une commande √©choue
   - `python -u` : Sortie non bufferis√©e (logs en temps r√©el)

3. **R√©sultat** : 8 runs distincts dans MLflow avec noms auto-g√©n√©r√©s :
   - `yolov8n_e3_sz320_lr0.005_s1`
   - `yolov8n_e3_sz320_lr0.005_s42`
   - `yolov8n_e3_sz320_lr0.01_s1`
   - `yolov8n_e3_sz320_lr0.01_s42`
   - `yolov8n_e3_sz416_lr0.005_s1`
   - `yolov8n_e3_sz416_lr0.005_s42`
   - `yolov8n_e3_sz416_lr0.01_s1`
   - `yolov8n_e3_sz416_lr0.01_s42`


---

## Analyse et comparaison des exp√©riences

### Comparaison dans l'UI MLflow

![Capture 4 - Comparaison des m√©triques](captures/4.png)


**M√©triques cl√©s analys√©es** :
- **mAP@50** : Pr√©cision moyenne √† 50% IoU (m√©trique principale)
- **mAP50-95** : Moyenne des mAP de 50% √† 95% IoU (plus stricte)
- **Precision** : Proportion de vraies d√©tections parmi les pr√©dictions positives
- **Recall** : Proportion de personnes d√©tect√©es parmi celles pr√©sentes

**Observations dans le tableau de comparaison** :
| Run                           | mAP@50 | mAP50-95 | Precision | Recall |
|-------------------------------|--------|----------|-----------|--------|
| `yolov8n_e3_sz320_lr0.005_s42` | 0.269  | 0.201    | 0.00841   | 0.720  |
| `yolov8n_e3_sz320_lr0.01_s42`  | 0.269  | 0.202    | 0.00842   | 0.726  |
| `yolov8n_e3_sz416_lr0.005_s42` | **0.303** | **0.257** | 0.00801   | **0.774** |
| `yolov8n_e3_sz416_lr0.01_s42`  | 0.244  | 0.204    | 0.00810   | 0.674  |

üèÜ **Meilleur run** : `yolov8n_e3_sz416_lr0.005_s42` (+11.5% mAP@50 vs 320√ó320)

### Visualisation des artifacts

![Capture 5 - Artifacts (graphiques)](captures/5.png)

**Artifacts logg√©s automatiquement** :
- **`results.png`** : Courbes de loss et m√©triques au fil des epochs
- **`confusion_matrix.png`** : Matrice de confusion (classe `person` vs background)
- **`PR_curve.png`** : Courbe Precision-Recall
- **`labels_correlogram.jpg`** : Distribution spatiale des labels

![Capture 6 - Artifacts (poids du mod√®le)](captures/6.png)

**Weights logg√©s** :
- **`weights/best.pt`** : Meilleur checkpoint (bas√© sur validation mAP)
- T√©l√©chargeable directement depuis MLflow pour d√©ploiement

**Avantages du logging d'artifacts** :
‚úÖ Reproductibilit√© : Retrouver les graphiques exacts d'un run ancien  
‚úÖ Debugging : Analyser la convergence et les patterns d'erreur  
‚úÖ D√©ploiement : R√©cup√©rer `best.pt` sans chercher dans les dossiers locaux

---

## D√©cision et promotion du mod√®le

### Rapport de d√©cision complet

üìÑ **[Voir le rapport de d√©cision d√©taill√©](reports/templates/decision_template.md)**

Le fichier `reports/templates/decision_template.md` contient une analyse exhaustive :

**Sections principales** :
1. **Objectifs et contraintes** : Maximiser mAP@50, contraintes de latence et budget
2. **Candidat promu** : `yolov8n_e3_sz416_lr0.005_s42`
3. **Comparaison d√©taill√©e** :
   - Configuration A : imgsz=320, lr=0.005 ‚Üí Performances inf√©rieures
   - Configuration B : imgsz=320, lr=0.01 ‚Üí Pas d'am√©lioration
   - **Configuration C** ‚≠ê : imgsz=416, lr=0.005 ‚Üí **RECOMMAND√âE**
   - Configuration D : imgsz=416, lr=0.01 ‚Üí Learning rate trop √©lev√©
4. **Analyse POUR/CONTRE** pour chaque configuration
5. **Risques identifi√©s et mitigations** :
   - Precision faible (0.8%) ‚Üí Augmenter threshold de confiance
   - Latence accrue ‚Üí Export ONNX/TensorRT
   - Sous-apprentissage (3 epochs) ‚Üí Re-entra√Æner avec 15-20 epochs
6. **Plan d'action** 

**Choix final justifi√©** :
> **Run** : `yolov8n_e3_sz416_lr0.005_s42`  
> **Justification** : +11.5% mAP@50, reproductibilit√© prouv√©e, stabilit√©, meilleur compromis performance/complexit√©

### Promotion dans le Model Registry

![Capture 7 - Model Registry](captures/7.png)


**Avantages du Model Registry** :
‚úÖ **Versioning** : Historique de tous les mod√®les d√©ploy√©s  
‚úÖ **Staging** : Tester en `Staging` avant promotion en `Production`  
‚úÖ **Audit trail** : Qui a promu quel mod√®le, quand et pourquoi  
‚úÖ **Rollback rapide** : Revenir √† une version pr√©c√©dente en 1 clic

---


